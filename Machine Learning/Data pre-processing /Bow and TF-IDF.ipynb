{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tiếng Việt** là một ngôn ngữ đặc biệt, có ngữ pháp phức tạp và có chút khác biệt (éo nhẹ) so với các hệ thống ngôn ngữ khác. Một từ của Tiếng Việt có thể được tạo hơn hai âm (tiếng), nếu bằng cách thông thường tách từ tiếng một thì các token có thể có nghĩa mới hoặc không có nghĩa. \n",
    "\n",
    "**Ví dụ:**\n",
    "    * mong manh => (mong, manh): một cặp từ không có nghĩa \n",
    "    * nhân ngư => (nhân, ngư): mỗi token mang nghĩa hoàn toàn khác.\n",
    "    \n",
    "Do đó chúng ta cần có một phương pháp có thể nhận ra 1 nhiều hơn 2 tiếng là một token.   \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram\n",
    "\n",
    "Mô hình ngôn ngữ thống kê cho phép ước lượng xác xuất cho một chuỗi $m$ phần tử (ta sẽ mặc định là từ) $P(w_1w_2…w_m)$, tức là sự đoán 1 câu (chuỗi các từ) xuất hiện trong ngôn ngữ đó.\n",
    "\n",
    "Ta có công thức Bayes:   $P(AB) = P(B|A)\\times P(A)$\n",
    "\n",
    "Với:\n",
    "* $P(A)$ Xác suất xảy ra sự kiện $A$\n",
    "* $P(B)$ Xác suất xảy ra sự kiện $B$\n",
    "* $P(B|A)$ Xác suất (có điều kiện) xảy ra sự kiện $B$ nếu biết rằng sự kiện \n",
    "$A$ đã xảy ra\n",
    "\n",
    "Suy ra: $P(w_1w_2…w_m) = P(w_1) * P(w_2|w_1) * P(w_3|w_1w_2) *…* P(w_m|w_1w_2…w_{m-1})$\n",
    "\n",
    "Trong thực tế, để lưu hết các trường hợp xảy ra của câu có độ dài nhỏ hơn m cần một dung lượng cực lớn, trong khi m không cố định và hoàn toàn có thể tiến tới vô cùng. Do vậy người ta sẽ sử dụng giả thuyết Markov để tính xác suất của một từ dựa vào nhiều nhát n từ xuất hiện trước đó, thông thường n = 1, 2, và 3. \n",
    "\n",
    "Công thức xấp xỉ markov bậc n:\n",
    "\n",
    "$P(w_m|w_1w_2…w_{m-1}) = P(w_m|w_{m-n}w_{m-n+1}…w_{m-1})$\n",
    "\n",
    "=> Công thức tính xác suất văn bản: $P(w_1w_2…w_m) = P(w_1) * P(w_2|w_1) * P(w_3|w_1w_2) *…* P(w_{m-1}|w_{m-n-1}w_{m-n} …w_{m-2})* P(w_m|w_{m-n}w_{m-n+1}…w_{m-1})$\n",
    "\n",
    "**Mô hình N-gram**\n",
    "* n = 1, unigram\n",
    "* n = 2, bigram\n",
    "* n = 3, trigram\n",
    "    \n",
    "**Ví dụ** Tính xác xuất của ***P(đèn| Một chiếc bóng đèn)***\n",
    "* Mô hình unigram: Một từ mà không phụ thuộc từ đứng trước nó thì ko có ngữ cảnh: P = P(đèn)\n",
    "* Mô hình bigram: Tính xác suất dựa vào một từ đứng trước nó: P = P(đèn|bóng)\n",
    "* Mô hình trigram: Tính xác xuất dwuaj vào hai từ trước nó P = P(đèn|chiếc bóng)\n",
    "\n",
    "Thông thường các mô hình bigram và trigram áp dụng tương đối nhiều cho các ngôn ngữ như Tiếng Việt, Tiếng Trung, Tiếng Nhật ...\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words \n",
    "\n",
    "**Bag of Words (Bow):** nó như là một bộ từ vựng của tất cả các văn bản, đếm số lần xuất hiện của các từ vựng trong văn bản đó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1]\n",
      " [0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 0]]\n",
      "{'all': 0, 'my': 11, 'cats': 2, 'in': 7, 'row': 14, 'when': 25, 'cat': 1, 'sits': 17, 'down': 3, 'she': 15, 'looks': 9, 'like': 8, 'furby': 6, 'toy': 24, 'the': 21, 'from': 5, 'outer': 12, 'space': 19, 'sunshine': 20, 'loves': 10, 'to': 23, 'sit': 16, 'this': 22, 'for': 4, 'some': 18, 'reason': 13}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "'All my cats in a row',\n",
    "'When my cat sits down, she looks like a Furby toy!',\n",
    "'The cat from outer space',\n",
    "'Sunshine loves to sit like this for some reason.'\n",
    "]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "print(vectorizer.fit_transform(corpus).todense() )\n",
    "print(vectorizer.vocabulary_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Một số lưu ý trong Bag of words\n",
    "* Trong thực tế, số lượng từ vựng của những ngôn ngữ rất nhiều, do đó từ điển sẽ cũng rất nhiền, việc tảo một vector đặc trưng cho từng câu cũng sẽ rất dài, bằng chiều dài của từ điển. \n",
    "* Có nhều từ sẽ rất hiểm gặp, những câu không có quá nhiều từ xuất hiện trong từ điển vẽ mang giá trị là 0, nếu > 50% chiều dài vector thì nó sẽ gây phản tác dụng.\n",
    "* Không mang thứ tự. Ví dụ hai câu **Tôi trèo lên cây** và **Cây trèo lên tôi** là không như nhau về mặt ngữ nghĩa nhưng lại có chung giá trị vector khi sử dụng BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (Term Frequency – Inverse Document Frequency)\n",
    "\n",
    "**TF-IDF** là kỹ thuật đánh giá tầm quan trọng của một từ trong một văn bản, Giá trị cao thể hiện độ quan trọng cao và nó phụ thuộc vào số lần từ xuất hiện trong văn bản nhưng bù lại bởi tần suất của từ đó trong tập dữ liệu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
