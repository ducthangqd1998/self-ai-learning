{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Neural Network - Mạng nơ-ron tích chập\n",
    "\n",
    "**Convolution Neural Network (CNN - Mạng nơ-ron tích chập)** là một trong những\n",
    "mô hình học sâu phổ biến giúp chúng ta xây dựng được các mô hình có độ chính\n",
    "xác cao, mang lại các kết quả đột phá trong lĩnh vực AI.\n",
    "\n",
    "Tích chập thông dụng nhất là tích chập 2 chiều được áp dụng trên ma trận đầu vào và ma trận bộ lọc 2 chiều. Phép tích chập của một ma trận $X\\in R^{W_1H_1}$ với một bộ lọc (receptive field) $F \\in R^{FF}$ là một ma trận $Y\\in R^{W_2H_2}$ sẽ trải qua những bước sau:\n",
    "\n",
    "* Tính tích chập tại 1 điểm: Tại vị trí đầu tiên trên cùng của ma trận đầu vào ta sẽ lọc ra một ma trận con $X_{sub} \\in R^{FF}$  có kích thước bằng với kích thước của bộ lọc. Giá trị $y_{11}$ tương ứng trên $Y$ là tích chập của $X_{sub}$ với $F$ được tính như sau:\n",
    "$$y_{11} = \\sum_{i=1}^F\\sum_{j=1}^F x_{ij}f_{ij}$$\n",
    "* Tiến hành trượt dọc theo ma trận theo chiều từ trái qua phải, từ trên xuống dưới theo bước nhảy (stride) $S$ ta sẽ tính được các giá trị $y_{ij}$ tiếp theo. Sau khi quá trình này kết thúc ta thu được trọn vẹn ma trận $Y$.\n",
    "\n",
    "Trong một mạng nơ ron tích chập, các lớp liền sau lấy đầu vào từ lớp liền trước nó. Do đó để hạn chế lỗi trong thiết kế mạng nơ ron chúng ta cần xác định kích thước đầu ra ở mỗi lớp. Điều đó có nghĩa là dựa vào kích thước ma trận đầu vào $(W_1,H_1)$, kích thước bộ lọc $(F,F)$ và bước nhảy $S$ để xác định kích thước ma trận đầu ra $(W_2,H_2)$.\n",
    "Xét quá trình trượt trên chiều $W1$ của ma trận đầu vào.\n",
    "\n",
    "<td> <img src=\"https://raw.githubusercontent.com/phamdinhkhanh/Tensorflow/master/ConvWidthStep.png\" alt=\"Drawing\" style=\"width: 70%;\"/> </td>\n",
    "\n",
    "Giả sử quá trình này sẽ dừng sau $W_2$ bước. Tại bước đầu tiên quá trình đi được đến vị trí thứ $F$. Sau mỗi bước liền sau sẽ tăng so với vị trí liền trước là $S$. Như vậy đến bước thứ $i$ quá trình trượt sẽ đi đến vị trí $F+(i−1)S$. Suy ra tại bước cuối cùng $W_2$ ma trận sẽ đi đến vị trí $F+(W_2−1)S$. Đây là vị trí lớn nhất gần với vị trí cuối cùng là $W_1$. Trong trường hợp lý tưởng thì $F+(W_2−1)S=W_1$. Từ đó ta suy ra:\n",
    "\n",
    "$$W_2 = \\frac{W_1-F}{S} + 1$$\n",
    "\n",
    "Khi về vị trí cuối cùng không trùng với $W_1$ thì số bước $W_2$ sẽ lấy được phần nguyên:\n",
    "\n",
    "$$W_2 = [\\frac{W_1-F}{S}] + 1$$\n",
    "\n",
    "Chúng ta luôn có thể tạo ra đẳng thức (1) nhờ thêm phần đường viền (padding) tại các cạnh của ảnh với độ rộng viền là $P$ sao cho phép chia cho $S$ là chia hết. Khi đó:\n",
    "\n",
    "$$W_2 = \\frac{W_1+2P-F}{S} + 1$$\n",
    "\n",
    "<td> <img src=\"https://raw.githubusercontent.com/phamdinhkhanh/Tensorflow/master/WidthPadding.png\" alt=\"Drawing\" style=\"width: 70%;\"/> </td>\n",
    "\n",
    "Hình 2: Thêm padding kích thước P vào 2 lề chiều rộng $(W_1)$\n",
    "\n",
    "Hoàn toàn tương tự ta cũng có công thức ứng với chiều cao:\n",
    "$$H_2 = \\frac{H_1+2P-F}{S} + 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Các layer (tầng) thường có ở một CNN**\n",
    "+ Convolution Layer (Lớp tích chập)\n",
    "+ Pooling Layer\n",
    "+ Normalization Layer\n",
    "+ Fully Connected Layer\n",
    "\n",
    "**Các khái niệm trong tích chập:**\n",
    "+ Kernel: Là ma trận vuông, chứa các giá trị thực hiện phép tính tích chập với\n",
    "ma trận ảnh, kích thước ma trận vuông này thường là 3x3.\n",
    "\n",
    "+ Stride (bước trượt): Khi trượt trên ma trận ảnh, ma trận bộ lọc sẽ trượt nhiều\n",
    "ô trên ma trận, số ô mà dịch sau mỗi lần trượt gọi là stride.\n",
    "\n",
    "+ Padding (Lề): Khi thực hiện phép tính tích chập 2 chiều, ma trận đầu ra luôn\n",
    "là một ma trận khác có kích thước nhỏ hơn ma trận ảnh là f-1 ở chiều cao và\n",
    "chiều rộng, trong đó f là kích thước hàng của ma trận bộ lọc. Để đảm bảo ma\n",
    "trận mới bằng kích thước ma trận ảnh, ta sẽ thêm các giá trị bằng 0 ở các\n",
    "phía, chỉ cần thêm f-1 tương đương mỗi phía thêm (f-1)/2. Hình 4 lấy ví dụ\n",
    "kernel có kích thước 3x3, padding=1 và stride=1.\n",
    "\n",
    "<td> <img src=\"https://miro.medium.com/max/790/1*1okwhewf5KCtIPaFib4XaA.gif\" alt=\"Drawing\" style=\"width: 30%;\"/> </td>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pooling Layer**\n",
    "- Để đơn giản hóa thông tin đầu ra sau mỗi lớp tích chập, người ta dùng pooling\n",
    "layer (lớp tổng hợp). Lớp này nhằm giảm số lượng neutrals, điều này rất hữu ích\n",
    "cho các ảnh có kích cỡ lớn (dimension reduction).\n",
    "- Thủ tục đơn giản nhất là max-pooling, với kích thước max-pooling là 2x2 thì với\n",
    "mỗi vùng chứa 2x2 pixel thì sẽ chọn ra giá trị lớn nhất cho ma trận đầu ra. Bằng\n",
    "cách thực hiện này thì kích thước ma trận sẽ giảm đi một nửa.\n",
    "- Chúng ta có thể thấy rằng Max Pooling là cách hỏi xem trong các đặc trưng này\n",
    "thì đặc trưng nào là đặc trưng nhất.\n",
    "- Lưu ý: Không nên quá lạm dụng layer này vì có thể khiến mất mát dữ liệu.\n",
    "<td> <img src=\"https://miro.medium.com/max/847/1*FHPUtGrVP6fRmVHDn3A7Rw.png\" alt=\"Drawing\" style=\"width: 50%;\"/> </td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalization Layer**\n",
    "- Việc trích xuất đặc trưng từ các lớp tích chập có thể gặp vấn đề về giá trị của các\n",
    "phần tử. Sẽ xuất hiện các phần tử có giá trị không thuộc khoảng ổn định (lớn hoặc\n",
    "nhỏ thất thường).\n",
    "- Như đã biết, để tinh chỉnh các trọng số ta thường sử dụng đạo hàm hàm. Nếu các\n",
    "ma trận đặc trưng chứa các giá trị thay đổi không ổn định thì dẫn đến các giá trị\n",
    "đạo hàm quá lớn hoặc quá nhỏ (trong khi chúng ta muốn giá trị xoay quanh giá\n",
    "trị 0) điều đó dẫn đến việc huấn luyện không ổn định, khó tối ưu.\n",
    "- Normalization Layer thường được sử dụng là Batch normalization giúp tránh hiện\n",
    "tượng các giá trị của ma trận đặc trưng rơi vào khoảng không ổn định trên. Điều\n",
    "này giúp chúng ta có nhiều thông tin, ổn định khi huấn luyện và kết quả tốt hơn\n",
    "khi dự đoán kết quả."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fully Connected Layer**\n",
    "- Fully Connected Layer: Cũng như các ANN truyền thống để xử lý những data\n",
    "có dạng matrix như image. Ta cần flatten data về dạng vector, sau đó đưa vào\n",
    "ANN như bình thường. Hay nói cách khác phần Fully-Connected Layer (FC\n",
    "Layer) chính là một mạng NN được gắn vào phần cuối của CNNs. Phần FC-Layer\n",
    "này chính là nơi từ các feature được extract bởi phần convolution và pooling tạo\n",
    "ra kết quả cuối cùng (Classification hoặc Regression).\n",
    "\n",
    "<td> <img src=\"https://i1.wp.com/nttuan8.com/wp-content/uploads/2019/03/flattern.png?resize=768%2C367&ssl=1\" alt=\"Drawing\" style=\"width: 50%;\"/> </td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualise CNN**\n",
    "\n",
    "Input image -> [[conv + ReLU]n -> Pooling]m -> [FC + ReLU]k -> FC -> Output\n",
    "<td> <img src=\"https://www.researchgate.net/publication/322848501/figure/fig2/AS:589054651420677@1517452981243/CNN-architecture-used-to-perform-image-classification-Ant-specimen-photograph-by-April.png\" alt=\"Drawing\" style=\"width: 90%;\"/> </td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nguồn tham khảo: \n",
    "* https://www.kaggle.com/phamdinhkhanh/convolutional-neural-network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
